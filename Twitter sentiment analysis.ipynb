{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6e8f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/z1xtr/Downloads/Naive_bayes/Naive_bayes/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7b6daf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03d3c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "449c55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c43ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1    Finally a transparant silicon case ^^ Thanks t...\n",
       "2    We love this! Would you go? #talk #makememorie...\n",
       "3    I'm wired I know I'm George I was made that wa...\n",
       "4    What amazing service! Apple won't even talk to...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e78d3a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "355204a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9bce68d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = '[{}]'.format(re.escape(string.punctuation))\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8efda077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stw = nltk.corpus.stopwords.words('english')\n",
    "print(stw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b005e",
   "metadata": {},
   "source": [
    "# Defining a function for text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db8a7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# converting the text into all lower cases\n",
    "\n",
    "def text_lower(text):\n",
    "    tlower = pd.Series([sents.lower() for sents in text])\n",
    "    return tlower\n",
    "\n",
    "# word tokenization\n",
    "\n",
    "def word_tkns(text):\n",
    "    tkns = pd.Series([nltk.tokenize.word_tokenize(sents) for sents in text])\n",
    "    return tkns\n",
    "\n",
    "# removing punctuation\n",
    "\n",
    "def punct_removal(text):\n",
    "    punct_pattern = '[{}]'.format(re.escape(string.punctuation))\n",
    "    regex_pattern = re.compile(punct_pattern)\n",
    "    clean_sents1= pd.Series([list(filter(None, [regex_pattern.sub('',  x) for x in sents])) for sents in text])\n",
    "    return clean_sents1\n",
    "\n",
    "# stopword removal\n",
    "# remember to not remove negations in the case of \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    clean_sents2 = pd.Series([[x for x in sents if x not in stopwords] for sents in text])\n",
    "    return clean_sents2\n",
    "\n",
    "\n",
    "## correcting words like spelling mistakes, repeated characters, etc. \n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "def remove_repeated_character(text):\n",
    "    \n",
    "    # pattern that occur twice among other characters\n",
    "    pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    replacement = r'\\1\\2\\3'\n",
    "    \n",
    "    def replace(tkn):\n",
    "        \n",
    "        # check semantically correct word if not replace and check again\n",
    "        if wn.synsets(tkn):\n",
    "            return tkn\n",
    "        \n",
    "        tkn_c = pattern.sub(replacement, tkn)\n",
    "        \n",
    "        # recursive call\n",
    "        return replace(tkn_c) if tkn_c != tkn else tkn_c\n",
    "    \n",
    "     # correct each token \n",
    "    token_c = pd.Series([[replace(tn) for tn in sents] for sents in text])\n",
    "    return token_c\n",
    "\n",
    "## PoS tagging\n",
    "\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    tkn_tagged = pd.Series([nltk.pos_tag(sents, tagset= 'universal') for sents in text])\n",
    "    \n",
    "    def penn_to_wn(ptag):\n",
    "        \n",
    "        if ptag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        if ptag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        if ptag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        if ptag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    tkn_tagged_wn = pd.Series([[(token, penn_to_wn(tag)) for token, tag in sents] for sents in tkn_tagged])\n",
    "    return tkn_tagged_wn\n",
    "                             \n",
    "## Lemmatization using WordNetLemmatizer\n",
    "\n",
    "def wnl(text):\n",
    "    wnlemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = pd.Series([[wnlemmatizer.lemmatize(words, tag) if tag else wnlemmatizer.lemmatize(words) for words, tag in sents ] for sents in text])\n",
    "    return stemmed_text                          \n",
    "\n",
    "# Converting earch element in the series from a list to string\n",
    "\n",
    "def list_to_string(text):\n",
    "    str_series = pd.Series([' '.join(sents) for sents in text])\n",
    "    return str_series\n",
    "    \n",
    "# Defining a function for text pre-processing\n",
    "\n",
    "def preprocessed_text(text):\n",
    "    \n",
    "    tl = text_lower(text)\n",
    "    wtkns = word_tkns(tl)\n",
    "    punc_removal = punct_removal(wtkns)\n",
    "    remove_stw = remove_stopwords(punc_removal)\n",
    "    removing_extra_characters = remove_repeated_character(remove_stw) \n",
    "    wn_tagged = pos_tag_text(removing_extra_characters)\n",
    "    lemmatized_text = wnl(wn_tagged)\n",
    "    preprocessed_text= list_to_string(lemmatized_text)\n",
    "    return preprocessed_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e615070",
   "metadata": {},
   "source": [
    "## Testing the function preprocessed_text(text) on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d02d5929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fingerprint pregnancy test http goglh1mfqv and...\n",
      "1    finally transparant silicon case thanks uncle ...\n",
      "2    love would go talk makememories unplug relax i...\n",
      "3    wire know george make way iphone cute daventry...\n",
      "4    amazing service apple wo nt even talk question...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "tweet_c = preprocessed_text(tweet)\n",
    "print(tweet_c[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09cf7f",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION USING TF-IDF MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d928ae",
   "metadata": {},
   "source": [
    "### Creating train and test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc526be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tweet_train, tweet_test, label_train, label_test = train_test_split(tweet_c, label, test_size= 0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0640b6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4015    love apple watch apple watch 42m excited chris...\n",
       "6898    girl demi lavato lavatic cute sexy fine music ...\n",
       "3779    new smartphone sony xperia new smartphone dj l...\n",
       "1611    2 gift birthday gift metome usa nike nikeair i...\n",
       "4204    backend vocation newyear trip thailand khaoko ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98c7e93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4015    0\n",
       "6898    0\n",
       "3779    0\n",
       "1611    0\n",
       "4204    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeccf2df",
   "metadata": {},
   "source": [
    "# Extracting features using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd33c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01' '0101' '0101am' '0101amay' '010315' '015' '01634' '02' '0230pm' '03'\n",
      " '0301am' '0301amjune' '030am' '0340pm' '04' '040am' '040pm' '0430pm'\n",
      " '0490love' '05' '051' '0530am' '06' '0630am' '069' '07' '070' '0701'\n",
      " '0701am' '0701amapril' '070am' '070pm' '0730pm' '07yilmaz242' '08'\n",
      " '0801amay' '0801pm' '0801pmapril' '0801pmjune' '080am' '080pm'\n",
      " '0818482028' '0830am' '0830pm' '09' '090pm' '0930am' '0g' '0x' '0ä1ö']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# creating an instance of TfidfVectorizer\n",
    "tfidfvectorizer = TfidfVectorizer(norm='l2', smooth_idf=True, use_idf=True)\n",
    "\n",
    "# using fit_transform method to extract the features from tweet-train\n",
    "features_train_t = tfidfvectorizer.fit_transform(tweet_train)\n",
    "features_train_tm = features_train_t.toarray()\n",
    "\n",
    "# tranforming the tweet-test\n",
    "features_test_t = tfidfvectorizer.transform(tweet_test)\n",
    "features_test_tm = features_test_t.toarray()\n",
    "\n",
    "# get feature names\n",
    "feature_names_t = tfidfvectorizer.get_feature_names_out()\n",
    "print(feature_names_t[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c319254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    01  0101  0101am  0101amay  010315  015  01634   02  0230pm   03\n",
      "0  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "1  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "2  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "3  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "4  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "    01  0101  0101am  0101amay  010315  015  01634   02  0230pm   03\n",
      "0  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "1  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "2  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "3  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n",
      "4  0.0   0.0     0.0       0.0     0.0  0.0    0.0  0.0     0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df_train_t = pd.DataFrame(data=features_train_tm, columns= feature_names_t)\n",
    "df_test_t = pd.DataFrame(data=features_test_tm, columns= feature_names_t)\n",
    "\n",
    "print(df_train_t.iloc[0:5, 0:10])\n",
    "print(df_test_t.iloc[0:5, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d2822",
   "metadata": {},
   "source": [
    "## Implement Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "304b9a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8303872053872053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create an instance of MultinomialNB()\n",
    "multinomialnb = MultinomialNB()\n",
    "\n",
    "# train the model\n",
    "multinomialnb.fit(features_train_t, label_train)\n",
    "# make_predictions\n",
    "predictions_t = multinomialnb.predict(features_test_t)\n",
    "\n",
    "# check accuracy\n",
    "as_t = accuracy_score(label_test, predictions_t)\n",
    "print('accuracy score:', as_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a992ac8",
   "metadata": {},
   "source": [
    "# classification matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9a3dc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1691</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>359</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1691   44\n",
       "1   359  282"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classification matrix\n",
    "from sklearn import metrics\n",
    "cm_multiNB = pd.DataFrame(data= metrics.confusion_matrix(label_test, predictions_t))\n",
    "cm_multiNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "85715a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z1xtr\\AppData\\Local\\Temp\\ipykernel_38088\\1918579730.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_predictions_check[df_predictions_check['label_t'] == 1][df_predictions_check['predicted_label'] == 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7539</th>\n",
       "      <td>skulcandy product brutal 1 headphone always st...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>ragin fbtwiterinsta aps phone aw card detail r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>mi iphone5 connect itunes geniusbar appointmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>go apple store fourth time wednesday getingold</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>nice line aps iphone aps fuckyou funny naughty...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>apple marketing best planet suck sucker apple ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>apple aplemusic overly complicate unreliable s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>dreamt emojis tripy af nt even iphone becausef...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>16gb iphone 5 sell 649 material worth 168 acco...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>phone fuck let type facebok twitter text</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  predicted_label  \\\n",
       "7539  skulcandy product brutal 1 headphone always st...                0   \n",
       "2464  ragin fbtwiterinsta aps phone aw card detail r...                0   \n",
       "6597  mi iphone5 connect itunes geniusbar appointmen...                0   \n",
       "554      go apple store fourth time wednesday getingold                0   \n",
       "2266  nice line aps iphone aps fuckyou funny naughty...                0   \n",
       "...                                                 ...              ...   \n",
       "5404  apple marketing best planet suck sucker apple ...                0   \n",
       "2925  apple aplemusic overly complicate unreliable s...                0   \n",
       "7176  dreamt emojis tripy af nt even iphone becausef...                0   \n",
       "3856  16gb iphone 5 sell 649 material worth 168 acco...                0   \n",
       "7775           phone fuck let type facebok twitter text                0   \n",
       "\n",
       "      label_t  \n",
       "7539        1  \n",
       "2464        1  \n",
       "6597        1  \n",
       "554         1  \n",
       "2266        1  \n",
       "...       ...  \n",
       "5404        1  \n",
       "2925        1  \n",
       "7176        1  \n",
       "3856        1  \n",
       "7775        1  \n",
       "\n",
       "[359 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total 359 wrong prediction for class 1\n",
    "df_predictions_check = pd.DataFrame({'tweet' : tweet_test, 'predicted_label' : predictions_t, 'label_t' : label_test})\n",
    "df_predictions_check[df_predictions_check['label_t'] == 1][df_predictions_check['predicted_label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2d959f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                    7540\n",
       "label                                                    1\n",
       "tweet    @skullcandy your product is brutal, 1 headphon...\n",
       "Name: 7539, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7539]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20dab849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                     555\n",
       "label                                                    1\n",
       "tweet    Have to go to the Apple Store for the fourth t...\n",
       "Name: 554, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[554]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf9a47",
   "metadata": {},
   "source": [
    "## Implement Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9588d316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8754208754208754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "bernoullinb2 = BernoulliNB()\n",
    "bernoullinb2.fit(features_train_t, label_train)\n",
    "predictions_bnb2 = bernoullinb2.predict(features_test_t)\n",
    "\n",
    "as_bnb2 = accuracy_score(label_test, predictions_bnb2)\n",
    "print('accuracy score:', as_bnb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99879b1",
   "metadata": {},
   "source": [
    "## classification matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b3e9796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1652</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1652   83\n",
       "1   213  428"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data= metrics.confusion_matrix(label_test, predictions_bnb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f75ba",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27b619a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.8813131313131313 \n",
      "precision score: 0.7774343122102009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "svm1 = SGDClassifier()\n",
    "svm1.fit(features_train_t, label_train)\n",
    "predictions_svm1 = svm1.predict(features_test_t)\n",
    "\n",
    "print('accuracy score:', metrics.accuracy_score(label_test, predictions_svm1), '\\nprecision score:', metrics.precision_score(label_test, predictions_svm1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737b66c",
   "metadata": {},
   "source": [
    "## classification matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3018b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1591</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1591  144\n",
       "1   138  503"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data= metrics.confusion_matrix(label_test, predictions_svm1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
